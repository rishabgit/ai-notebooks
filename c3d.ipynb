{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1337\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1337"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import seed_everything\n",
    "import torchmetrics\n",
    "from torchinfo import summary\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed_everything(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C3D(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    https://arxiv.org/abs/1412.0767\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=487):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv3d(3, 64, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool1 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
    "\n",
    "        self.conv2 = nn.Conv3d(64, 128, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool2 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
    "\n",
    "        self.conv3a = nn.Conv3d(128, 256, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.conv3b = nn.Conv3d(256, 256, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool3 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
    "\n",
    "        self.conv4a = nn.Conv3d(256, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.conv4b = nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool4 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
    "\n",
    "        self.conv5a = nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.conv5b = nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool5 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=(0, 1, 1))\n",
    "\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "\n",
    "        self.fc6 = nn.Linear(8192, 4096)\n",
    "        self.fc7 = nn.Linear(4096, 4096)\n",
    "        self.fc8 = nn.Linear(4096, num_classes)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "        self.acc = torchmetrics.Accuracy()\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    def init_weight(self):\n",
    "        for name, para in self.named_parameters():\n",
    "            if name.find('weight') != -1:\n",
    "                nn.init.xavier_normal_(para.data)\n",
    "            else:\n",
    "                nn.init.constant_(para.data, 0)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.relu(self.conv3a(x))\n",
    "        x = self.relu(self.conv3b(x))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = self.relu(self.conv4a(x))\n",
    "        x = self.relu(self.conv4b(x))\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        x = self.relu(self.conv5a(x))\n",
    "        x = self.relu(self.conv5b(x))\n",
    "        x = self.pool5(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc6(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc7(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc8(x)\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.relu(self.conv3a(x))\n",
    "        x = self.relu(self.conv3b(x))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = self.relu(self.conv4a(x))\n",
    "        x = self.relu(self.conv4b(x))\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        x = self.relu(self.conv5a(x))\n",
    "        x = self.relu(self.conv5b(x))\n",
    "        x = self.pool5(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc6(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc7(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc8(x)\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        train_loss = self.loss(y, x)\n",
    "        acc = self.acc(y, x)\n",
    "        self.log_dict({\"acc\": acc, \"train_loss\": train_loss}, prog_bar=True)\n",
    "        return train_loss\n",
    "\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.relu(self.conv3a(x))\n",
    "        x = self.relu(self.conv3b(x))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = self.relu(self.conv4a(x))\n",
    "        x = self.relu(self.conv4b(x))\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        x = self.relu(self.conv5a(x))\n",
    "        x = self.relu(self.conv5b(x))\n",
    "        x = self.pool5(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc6(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc7(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc8(x)\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        val_loss = self.loss(y, x)\n",
    "        mae = self.mae(y*6, x*6)\n",
    "        self.log_dict({\"mae\": mae, \"val_loss\": val_loss}, prog_bar=True)\n",
    "        return val_loss\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=0.003)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.1)\n",
    "        return {\n",
    "            \"optimizer\":optimizer,\n",
    "            \"lr_scheduler\" : {\n",
    "                \"scheduler\" : scheduler,\n",
    "                \"monitor\" : \"train_loss\",\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = C3D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "C3D                                      [1, 487]                  18,776,551\n",
      "├─Conv3d: 1-1                            [1, 64, 16, 112, 112]     5,248\n",
      "├─ReLU: 1-2                              [1, 64, 16, 112, 112]     --\n",
      "├─MaxPool3d: 1-3                         [1, 64, 16, 56, 56]       --\n",
      "├─Conv3d: 1-4                            [1, 128, 16, 56, 56]      221,312\n",
      "├─ReLU: 1-5                              [1, 128, 16, 56, 56]      --\n",
      "├─MaxPool3d: 1-6                         [1, 128, 8, 28, 28]       --\n",
      "├─Conv3d: 1-7                            [1, 256, 8, 28, 28]       884,992\n",
      "├─ReLU: 1-8                              [1, 256, 8, 28, 28]       --\n",
      "├─Conv3d: 1-9                            [1, 256, 8, 28, 28]       1,769,728\n",
      "├─ReLU: 1-10                             [1, 256, 8, 28, 28]       --\n",
      "├─MaxPool3d: 1-11                        [1, 256, 4, 14, 14]       --\n",
      "├─Conv3d: 1-12                           [1, 512, 4, 14, 14]       3,539,456\n",
      "├─ReLU: 1-13                             [1, 512, 4, 14, 14]       --\n",
      "├─Conv3d: 1-14                           [1, 512, 4, 14, 14]       7,078,400\n",
      "├─ReLU: 1-15                             [1, 512, 4, 14, 14]       --\n",
      "├─Linear: 1-31                           [1, 4096]                 (recursive)\n",
      "├─Linear: 1-34                           [1, 487]                  (recursive)\n",
      "├─Dropout: 1-33                          [1, 4096]                 --\n",
      "├─MaxPool3d: 1-19                        [1, 512, 2, 7, 7]         --\n",
      "├─Conv3d: 1-20                           [1, 512, 2, 7, 7]         7,078,400\n",
      "├─Accuracy: 1-21                         --                        --\n",
      "├─CrossEntropyLoss: 1-22                 --                        --\n",
      "├─ReLU: 1-23                             [1, 512, 2, 7, 7]         --\n",
      "├─Conv3d: 1-24                           [1, 512, 2, 7, 7]         7,078,400\n",
      "├─ReLU: 1-25                             [1, 512, 2, 7, 7]         --\n",
      "├─MaxPool3d: 1-26                        [1, 512, 1, 4, 4]         --\n",
      "├─Flatten: 1-27                          [1, 8192]                 --\n",
      "├─Linear: 1-28                           [1, 4096]                 33,558,528\n",
      "├─ReLU: 1-29                             [1, 4096]                 --\n",
      "├─Dropout: 1-30                          [1, 4096]                 --\n",
      "├─Linear: 1-31                           [1, 4096]                 (recursive)\n",
      "├─ReLU: 1-32                             [1, 4096]                 --\n",
      "├─Dropout: 1-33                          [1, 4096]                 --\n",
      "├─Linear: 1-34                           [1, 487]                  (recursive)\n",
      "├─Softmax: 1-35                          [1, 487]                  --\n",
      "==========================================================================================\n",
      "Total params: 79,991,015\n",
      "Trainable params: 79,991,015\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 38.59\n",
      "==========================================================================================\n",
      "Input size (MB): 2.41\n",
      "Forward/backward pass size (MB): 187.09\n",
      "Params size (MB): 244.86\n",
      "Estimated Total Size (MB): 434.36\n",
      "==========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33727/3408171904.py:75: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.softmax(x)\n"
     ]
    }
   ],
   "source": [
    "print(summary(model, input_size=(1, 3, 16, 112, 112)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# short ucf101 downloaded from here- https://www.kaggle.com/datasets/nguyntindng0506/ucf101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        dataset (str): Name of dataset. Defaults to 'ucf101'.\n",
    "        split (str): Determines which folder of the directory the dataset will read from. Defaults to 'train'.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset='data', split='train'):\n",
    "        self.root_dir = dataset\n",
    "        self.split = split\n",
    "\n",
    "        # Section 3.2. \"Training\"\n",
    "        self.resize_height = 128\n",
    "        self.resize_width = 171\n",
    "        self.crop_size = 112\n",
    "\n",
    "        if split == 'train':\n",
    "            self.h_flip = transforms.RandomHorizontalFlip(p=0.5)\n",
    "        self.img_tfs = transforms.Compose([\n",
    "                    transforms.ToPILImage(),\n",
    "                    transforms.Resize((128, 171)),\n",
    "                    transforms.CenterCrop((112, 112)),\n",
    "                ])\n",
    "\n",
    "        self.fnames, labels = [], []\n",
    "        for fname in sorted(os.listdir(os.path.join(self.root_dir, split))):\n",
    "            self.fnames.append(os.path.join(self.root_dir, split, fname))\n",
    "            labels.append(fname.split(\"_\")[1])\n",
    "\n",
    "        print(f'Number of {split}: {len(self.fnames)}')\n",
    "        print(f'Available label classes: {sorted(list(set(labels)))}')\n",
    "\n",
    "        # Prepare a mapping between the label names (strings) and indices (ints)\n",
    "        self.label2index = {label: index for index, label in enumerate(sorted(set(labels)))}\n",
    "        # Convert the list of label names into an array of label indices\n",
    "        self.label_array = np.array([self.label2index[label] for label in labels], dtype=int)\n",
    "        assert len(self.label_array) == len(self.fnames)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fnames)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        subsampled_frames = [] # 16, 112, 112\n",
    "        for frame in self.process_video(self.fnames[index]):\n",
    "            frame = self.img_tfs(frame)\n",
    "            if self.split == 'train':\n",
    "                frame = self.h_flip(frame)\n",
    "            frame = np.array(frame)\n",
    "            frame = frame / 255. # paper doesn't say anything about normalization\n",
    "            subsampled_frames.append(frame)\n",
    "\n",
    "        subsampled_frames = np.array(subsampled_frames)\n",
    "        labels = np.array(self.label_array[index])\n",
    "        return torch.from_numpy(subsampled_frames), torch.from_numpy(labels)\n",
    "\n",
    "\n",
    "    def process_video(self, fname):\n",
    "        subsampled_frames = []\n",
    "        capture = cv2.VideoCapture(fname)\n",
    "        frame_count = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        count = 0\n",
    "        frames_to_keep = self.frames_splits(frame_count, 16)\n",
    "        while count < frame_count:\n",
    "            ret, frame = capture.read()\n",
    "            if frame is None or not ret:\n",
    "                continue\n",
    "            count += 1\n",
    "            # Section 3.1. \"Common network settings\" \n",
    "            if count in frames_to_keep:\n",
    "                subsampled_frames.append(frame)\n",
    "        capture.release()\n",
    "        return subsampled_frames\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def frames_splits(a, n):\n",
    "        k, m = divmod(a, n)\n",
    "        return [(i+1)*k+min(i+1, m) for i in range(n)]\n",
    "\n",
    "\n",
    "    def to_tensor(self, buffer):\n",
    "        return buffer.transpose((3, 0, 1, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train: 594\n",
      "Available label classes: ['CricketShot', 'PlayingCello', 'Punch', 'ShavingBeard', 'TennisSwing']\n"
     ]
    }
   ],
   "source": [
    "dataset = VideoDataset('data')\n",
    "x, y = next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52c1536be2703022bdc2410894b56c577b65ee369faba254cdff0f9aec6fe983"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
