{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1337\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1337"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import seed_everything\n",
    "import torchmetrics\n",
    "from torchinfo import summary\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "seed_everything(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C3D(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    https://arxiv.org/abs/1412.0767\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=487):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv3d(3, 64, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool1 = nn.MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2))\n",
    "\n",
    "        self.conv2 = nn.Conv3d(64, 128, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool2 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
    "\n",
    "        self.conv3a = nn.Conv3d(128, 256, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.conv3b = nn.Conv3d(256, 256, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool3 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
    "\n",
    "        self.conv4a = nn.Conv3d(256, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.conv4b = nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool4 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
    "\n",
    "        self.conv5a = nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.conv5b = nn.Conv3d(512, 512, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n",
    "        self.pool5 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=(0, 1, 1))\n",
    "\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "\n",
    "        self.fc6 = nn.Linear(8192, 4096)\n",
    "        self.fc7 = nn.Linear(4096, 4096)\n",
    "        self.fc8 = nn.Linear(4096, num_classes)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        self.acc = torchmetrics.Accuracy()\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    def init_weight(self):\n",
    "        for name, para in self.named_parameters():\n",
    "            if name.find('weight') != -1:\n",
    "                nn.init.xavier_normal_(para.data)\n",
    "            else:\n",
    "                nn.init.constant_(para.data, 0)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.relu(self.conv3a(x))\n",
    "        x = self.relu(self.conv3b(x))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = self.relu(self.conv4a(x))\n",
    "        x = self.relu(self.conv4b(x))\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        x = self.relu(self.conv5a(x))\n",
    "        x = self.relu(self.conv5b(x))\n",
    "        x = self.pool5(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc6(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc7(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc8(x)\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.relu(self.conv3a(x))\n",
    "        x = self.relu(self.conv3b(x))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = self.relu(self.conv4a(x))\n",
    "        x = self.relu(self.conv4b(x))\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        x = self.relu(self.conv5a(x))\n",
    "        x = self.relu(self.conv5b(x))\n",
    "        x = self.pool5(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc6(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc7(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc8(x)\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        train_loss = self.loss(x, y)\n",
    "        train_acc = self.acc(x, y)\n",
    "        self.log_dict({\"train_acc\": train_acc, \"train_loss\": train_loss}, prog_bar=True)\n",
    "        return train_loss\n",
    "\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.relu(self.conv3a(x))\n",
    "        x = self.relu(self.conv3b(x))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = self.relu(self.conv4a(x))\n",
    "        x = self.relu(self.conv4b(x))\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        x = self.relu(self.conv5a(x))\n",
    "        x = self.relu(self.conv5b(x))\n",
    "        x = self.pool5(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc6(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc7(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc8(x)\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        val_loss = self.loss(x, y)\n",
    "        val_acc = self.acc(x, y)\n",
    "        self.log_dict({\"val_acc\": val_acc, \"val_loss\": val_loss}, prog_bar=True)\n",
    "        return val_loss\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # lr as written in paper\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=0.003)\n",
    "        # not super sure about the step_size\n",
    "        # correct according to Section 3.1. \"Common network settings\" \n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.1)\n",
    "        return {\n",
    "            \"optimizer\":optimizer,\n",
    "            \"lr_scheduler\" : {\n",
    "                \"scheduler\" : scheduler,\n",
    "                \"monitor\" : \"train_loss\",\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# short ucf101 downloaded from here- https://www.kaggle.com/datasets/nguyntindng0506/ucf101\n",
    "\n",
    "class VideoDataset(Dataset):\n",
    "    \"\"\"\n",
    "    https://www.kaggle.com/datasets/nguyntindng0506/ucf101\n",
    "    Args:\n",
    "        dataset (str): Name of dataset. Defaults to 'ucf101'.\n",
    "        split (str): Determines which folder of the directory the dataset will read from. Defaults to 'train'.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset='data', split='train'):\n",
    "        self.root_dir = dataset\n",
    "        self.split = split\n",
    "\n",
    "        # Section 3.2. \"Training\"\n",
    "        self.resize_height = 128\n",
    "        self.resize_width = 171\n",
    "        self.crop_size = 112\n",
    "\n",
    "        if split == 'train':\n",
    "            self.h_flip = transforms.RandomHorizontalFlip(p=0.5)\n",
    "        self.img_tfs = transforms.Compose([\n",
    "                    transforms.ToPILImage(),\n",
    "                    transforms.Resize((128, 171)),\n",
    "                    transforms.CenterCrop((112, 112)),\n",
    "                ])\n",
    "\n",
    "        print('Loading and processing videos...')\n",
    "        self.fnames, labels = [], []\n",
    "        # load videos now - loading/processing vids during training ate up a lot of time\n",
    "        # unsure if loading/processing everything NOW makes sense either\n",
    "        # especially when dataset size is big\n",
    "        for fname in tqdm(sorted(os.listdir(os.path.join(self.root_dir, split)))):\n",
    "            video_frames_chunk = self.process_video(os.path.join(self.root_dir, split, fname))\n",
    "            # ignoring videos which have missing frames\n",
    "            if len(video_frames_chunk) == 16: \n",
    "                self.fnames.append(video_frames_chunk)\n",
    "                labels.append(fname.split(\"_\")[1])\n",
    "\n",
    "        print(f'Number of {split}: {len(self.fnames)}')\n",
    "        print(f'Available label classes: {sorted(list(set(labels)))}')\n",
    "\n",
    "        # Prepare a mapping between the label names (strings) and indices (ints)\n",
    "        self.label2index = {label: index for index, label in enumerate(sorted(set(labels)))}\n",
    "        # Convert the list of label names into an array of label indices\n",
    "        self.label_array = np.array([self.label2index[label] for label in labels], dtype=int)\n",
    "        assert len(self.label_array) == len(self.fnames)\n",
    "\n",
    "\n",
    "\n",
    "    def num_classes(self):\n",
    "        return len(list(set(self.label_array)))\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fnames)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        subsampled_frames = [] # 16, 112, 112\n",
    "        for frame in self.fnames[index]:\n",
    "            frame = self.img_tfs(frame)\n",
    "            if self.split == 'train':\n",
    "                frame = self.h_flip(frame)\n",
    "            frame = np.array(frame)\n",
    "            frame = frame / 255. # paper doesn't say anything about normalization\n",
    "            subsampled_frames.append(frame)\n",
    "        # reshape into (C, D, H, W) for easier convolutions\n",
    "        subsampled_frames = np.array(subsampled_frames).transpose((3, 0, 1, 2)) \n",
    "        labels = np.array(self.label_array[index])\n",
    "        return torch.from_numpy(subsampled_frames).float(), torch.from_numpy(labels).type(torch.LongTensor)\n",
    "\n",
    "\n",
    "    def process_video(self, fname):\n",
    "        subsampled_frames = []\n",
    "        capture = cv2.VideoCapture(fname)\n",
    "        frame_count = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        count = 0\n",
    "        frames_to_keep = self.frames_splits(frame_count, 16)\n",
    "        while capture.isOpened():\n",
    "            ret, frame = capture.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            count += 1\n",
    "            # Section 3.1. \"Common network settings\" \n",
    "            if count in frames_to_keep:\n",
    "                subsampled_frames.append(frame)\n",
    "        capture.release()\n",
    "        return subsampled_frames\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def frames_splits(a, n):\n",
    "        k, m = divmod(a, n)\n",
    "        return [(i+1)*k+min(i+1, m) for i in range(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and processing videos...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d08aec62647745f4a02f13db9b964afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/224 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test: 218\n",
      "Available label classes: ['CricketShot', 'PlayingCello', 'Punch', 'ShavingBeard', 'TennisSwing']\n"
     ]
    }
   ],
   "source": [
    "val_set = VideoDataset('data', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and processing videos...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b242accf7f64e76aadfc7a0ac2bf3d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train: 575\n",
      "Available label classes: ['CricketShot', 'PlayingCello', 'Punch', 'ShavingBeard', 'TennisSwing']\n"
     ]
    }
   ],
   "source": [
    "train_set = VideoDataset('data', 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(575, 218, 5, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set), len(val_set), train_set.num_classes(), val_set.num_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "C3D                                      [10, 5]                   16,801,797\n",
      "├─Conv3d: 1-1                            [10, 64, 16, 112, 112]    5,248\n",
      "├─ReLU: 1-2                              [10, 64, 16, 112, 112]    --\n",
      "├─MaxPool3d: 1-3                         [10, 64, 16, 56, 56]      --\n",
      "├─Conv3d: 1-4                            [10, 128, 16, 56, 56]     221,312\n",
      "├─ReLU: 1-5                              [10, 128, 16, 56, 56]     --\n",
      "├─MaxPool3d: 1-6                         [10, 128, 8, 28, 28]      --\n",
      "├─Conv3d: 1-7                            [10, 256, 8, 28, 28]      884,992\n",
      "├─ReLU: 1-8                              [10, 256, 8, 28, 28]      --\n",
      "├─Conv3d: 1-9                            [10, 256, 8, 28, 28]      1,769,728\n",
      "├─ReLU: 1-10                             [10, 256, 8, 28, 28]      --\n",
      "├─MaxPool3d: 1-11                        [10, 256, 4, 14, 14]      --\n",
      "├─Conv3d: 1-12                           [10, 512, 4, 14, 14]      3,539,456\n",
      "├─ReLU: 1-13                             [10, 512, 4, 14, 14]      --\n",
      "├─Conv3d: 1-14                           [10, 512, 4, 14, 14]      7,078,400\n",
      "├─ReLU: 1-15                             [10, 512, 4, 14, 14]      --\n",
      "├─Linear: 1-31                           [10, 4096]                (recursive)\n",
      "├─Linear: 1-34                           [10, 5]                   (recursive)\n",
      "├─Dropout: 1-33                          [10, 4096]                --\n",
      "├─MaxPool3d: 1-19                        [10, 512, 2, 7, 7]        --\n",
      "├─Conv3d: 1-20                           [10, 512, 2, 7, 7]        7,078,400\n",
      "├─Accuracy: 1-21                         --                        --\n",
      "├─CrossEntropyLoss: 1-22                 --                        --\n",
      "├─ReLU: 1-23                             [10, 512, 2, 7, 7]        --\n",
      "├─Conv3d: 1-24                           [10, 512, 2, 7, 7]        7,078,400\n",
      "├─ReLU: 1-25                             [10, 512, 2, 7, 7]        --\n",
      "├─MaxPool3d: 1-26                        [10, 512, 1, 4, 4]        --\n",
      "├─Flatten: 1-27                          [10, 8192]                --\n",
      "├─Linear: 1-28                           [10, 4096]                33,558,528\n",
      "├─ReLU: 1-29                             [10, 4096]                --\n",
      "├─Dropout: 1-30                          [10, 4096]                --\n",
      "├─Linear: 1-31                           [10, 4096]                (recursive)\n",
      "├─ReLU: 1-32                             [10, 4096]                --\n",
      "├─Dropout: 1-33                          [10, 4096]                --\n",
      "├─Linear: 1-34                           [10, 5]                   (recursive)\n",
      "├─Softmax: 1-35                          [10, 5]                   --\n",
      "==========================================================================================\n",
      "Total params: 78,016,261\n",
      "Trainable params: 78,016,261\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 385.87\n",
      "==========================================================================================\n",
      "Input size (MB): 24.08\n",
      "Forward/backward pass size (MB): 1870.89\n",
      "Params size (MB): 244.86\n",
      "Estimated Total Size (MB): 2139.83\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "model = C3D(num_classes=train_set.num_classes())\n",
    "print(summary(model, input_size=(10, 3, 16, 112, 112)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=4, shuffle=True, num_workers=16)\n",
    "val_loader = DataLoader(val_set, batch_size=4, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y = next(iter(train_loader))\n",
    "# x.shape, y.shape, y.type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(limit_train_batches=100, max_epochs=16,accelerator='gpu', devices=1, log_every_n_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf lightning_logs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: /home/rishab/Documents/codes/model-arch-implementation/quick-model-archs/c3d/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name    | Type             | Params\n",
      "----------------------------------------------\n",
      "0  | conv1   | Conv3d           | 5.2 K \n",
      "1  | pool1   | MaxPool3d        | 0     \n",
      "2  | conv2   | Conv3d           | 221 K \n",
      "3  | pool2   | MaxPool3d        | 0     \n",
      "4  | conv3a  | Conv3d           | 884 K \n",
      "5  | conv3b  | Conv3d           | 1.8 M \n",
      "6  | pool3   | MaxPool3d        | 0     \n",
      "7  | conv4a  | Conv3d           | 3.5 M \n",
      "8  | conv4b  | Conv3d           | 7.1 M \n",
      "9  | pool4   | MaxPool3d        | 0     \n",
      "10 | conv5a  | Conv3d           | 7.1 M \n",
      "11 | conv5b  | Conv3d           | 7.1 M \n",
      "12 | pool5   | MaxPool3d        | 0     \n",
      "13 | flatten | Flatten          | 0     \n",
      "14 | fc6     | Linear           | 33.6 M\n",
      "15 | fc7     | Linear           | 16.8 M\n",
      "16 | fc8     | Linear           | 20.5 K\n",
      "17 | dropout | Dropout          | 0     \n",
      "18 | relu    | ReLU             | 0     \n",
      "19 | softmax | Softmax          | 0     \n",
      "20 | acc     | Accuracy         | 0     \n",
      "21 | loss    | CrossEntropyLoss | 0     \n",
      "----------------------------------------------\n",
      "78.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "78.0 M    Total params\n",
      "312.065   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 155/155 [00:15<00:00, 10.00it/s, loss=1.61, v_num=0, train_acc=0.250, train_loss=1.610, val_acc=0.202, val_loss=1.610]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=16` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 155/155 [00:16<00:00,  9.68it/s, loss=1.61, v_num=0, train_acc=0.250, train_loss=1.610, val_acc=0.202, val_loss=1.610]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model=model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "# run 'tensorboard --logdir .' on terminal for logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52c1536be2703022bdc2410894b56c577b65ee369faba254cdff0f9aec6fe983"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
